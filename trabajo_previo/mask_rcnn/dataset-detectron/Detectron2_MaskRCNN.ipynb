{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Detectron2_MaskRCNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Instalar"],"metadata":{"id":"l4u_BCnjXIWh"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oFM0U7w5Vzfc","executionInfo":{"status":"ok","timestamp":1640910447958,"user_tz":180,"elapsed":27942,"user":{"displayName":"Omar Pavez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16127216402199155313"}},"outputId":"56f65551-93eb-4194-9ab6-4a6139d13204"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 5.5 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=50eefab0ba0699d6ed65646c951e1102087a82ee358e1d5759b75cfc37f8092d\n","  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","torch:  1.10 ; cuda:  cu111\n","Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n","Collecting detectron2\n","  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (7.0 MB)\n","\u001b[K     |████████████████████████████████| 7.0 MB 772 kB/s \n","\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n","Collecting yacs>=0.1.8\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting omegaconf>=2.1\n","  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 2.2 MB/s \n","\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n","Collecting fvcore<0.1.6,>=0.1.5\n","  Downloading fvcore-0.1.5.post20211023.tar.gz (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.7.0)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n","Collecting black==21.4b2\n","  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n","\u001b[K     |████████████████████████████████| 130 kB 11.5 MB/s \n","\u001b[?25hCollecting hydra-core>=1.1\n","  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 47.3 MB/s \n","\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n","Collecting mypy-extensions>=0.4.3\n","  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n","Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n","Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n","Collecting typed-ast>=1.4.2\n","  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n","\u001b[K     |████████████████████████████████| 843 kB 48.1 MB/s \n","\u001b[?25hCollecting regex>=2020.1.8\n","  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n","\u001b[K     |████████████████████████████████| 749 kB 42.7 MB/s \n","\u001b[?25hCollecting pathspec<1,>=0.8.1\n","  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.19.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 53.1 MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (57.4.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.24)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.6.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.42.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.12.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.8.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.1)\n","Building wheels for collected packages: fvcore, antlr4-python3-runtime\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20211023-py3-none-any.whl size=60947 sha256=56abe62dc2debcbe56304b05b1a9b16a4f6f84a1992723b0bbd46166fe8df7db\n","  Stored in directory: /root/.cache/pip/wheels/16/98/fc/252d62cab6263c719120e06b28f3378af59b52ce7a20e81852\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=b30904f42364876dba45a76512c6c3de16ec357d543622cf78027cebc22d6fa9\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","Successfully built fvcore antlr4-python3-runtime\n","Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20211023 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.3.2 regex-2021.11.10 typed-ast-1.5.1 yacs-0.1.8\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["!pip install pyyaml==5.1\n","\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","# Install detectron2 that matches the above pytorch version\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n","# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n","\n","# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"]},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"1Y2UlFWyXKyc"}},{"cell_type":"code","source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"metadata":{"id":"K_KUK81DWvbL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cargar dataset"],"metadata":{"id":"bCEhEypzXMYY"}},{"cell_type":"code","source":["from detectron2.data import MetadataCatalog, DatasetCatalog\n","\n","dir_path = \"/content/drive/MyDrive/Mask RCNN/dataset-detectron/\"\n","\n","def load_data(t=\"train\"):\n","    if t == \"train\":\n","        with open(dir_path+\"dataset.json\", 'r') as file:\n","            train = json.load(file)[\"train\"]\n","        return train\n","    elif t == \"val\":\n","      with open(dir_path+\"dataset.json\", 'r') as file:\n","          val = json.load(file)[\"val\"]\n","    return val\n","\n","\n","for d in [\"train\", \"val\"]:\n","    DatasetCatalog.register(d, lambda d=d: load_data(d))\n","    MetadataCatalog.get(d).set(thing_classes=[\"Uva\"])\n","metadata = MetadataCatalog.get(\"train\")"],"metadata":{"id":"sbCdcVJ_XM3V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Configs"],"metadata":{"id":"TLMraw19XXYa"}},{"cell_type":"code","source":["\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"train\",)\n","cfg.DATASETS.TEST = (\"val\",)\n","cfg.DATALOADER.NUM_WORKERS = 1\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n","cfg.SOLVER.IMS_PER_BATCH = 1\n","cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n","cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n","cfg.SOLVER.STEPS = []        # do not decay learning rate\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n","cfg.OUTPUT_DIR = \"/content/drive/MyDrive/Mask RCNN/dataset-detectron/output\"\n","# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"],"metadata":{"id":"CFj9OzgOXX75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train"],"metadata":{"id":"NeQTreMOY5PP"}},{"cell_type":"code","source":["from detectron2.engine import DefaultTrainer\n","\n","\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AY4K5qnuY8V2","executionInfo":{"status":"ok","timestamp":1640735072276,"user_tz":180,"elapsed":200391,"user":{"displayName":"Omar Pavez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16127216402199155313"}},"outputId":"bd81f9fb-5770-4848-c3ec-c315f661ddf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[12/28 23:41:15 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[32m[12/28 23:41:16 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 24 images left.\n","\u001b[32m[12/28 23:41:16 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    Uva     | 2239         |\n","|            |              |\u001b[0m\n","\u001b[32m[12/28 23:41:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[12/28 23:41:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[12/28 23:41:16 d2.data.common]: \u001b[0mSerializing 24 elements to byte tensors and concatenating them all ...\n","\u001b[32m[12/28 23:41:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.47 MiB\n"]},{"output_type":"stream","name":"stderr","text":["Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[12/28 23:41:23 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[12/28 23:41:38 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 19  total_loss: 4.133  loss_cls: 0.6956  loss_box_reg: 0.4837  loss_mask: 0.6919  loss_rpn_cls: 1.96  loss_rpn_loc: 0.1858  time: 0.6840  data_time: 0.1419  lr: 1.6068e-05  max_mem: 1705M\n","\u001b[32m[12/28 23:41:50 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 39  total_loss: 2.215  loss_cls: 0.6319  loss_box_reg: 0.5981  loss_mask: 0.6542  loss_rpn_cls: 0.1319  loss_rpn_loc: 0.1632  time: 0.6522  data_time: 0.0269  lr: 3.2718e-05  max_mem: 1705M\n","\u001b[32m[12/28 23:42:03 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 59  total_loss: 2  loss_cls: 0.5345  loss_box_reg: 0.6321  loss_mask: 0.5781  loss_rpn_cls: 0.1374  loss_rpn_loc: 0.1519  time: 0.6513  data_time: 0.0042  lr: 4.9367e-05  max_mem: 1705M\n","\u001b[32m[12/28 23:42:15 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 79  total_loss: 1.869  loss_cls: 0.4892  loss_box_reg: 0.6176  loss_mask: 0.4896  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.1461  time: 0.6325  data_time: 0.0048  lr: 6.6017e-05  max_mem: 1705M\n","\u001b[32m[12/28 23:42:27 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 99  total_loss: 1.769  loss_cls: 0.4473  loss_box_reg: 0.6147  loss_mask: 0.4465  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.1486  time: 0.6237  data_time: 0.0046  lr: 8.2668e-05  max_mem: 1705M\n","\u001b[32m[12/28 23:42:40 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 119  total_loss: 1.59  loss_cls: 0.3889  loss_box_reg: 0.6115  loss_mask: 0.3933  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1403  time: 0.6255  data_time: 0.0054  lr: 9.9318e-05  max_mem: 1705M\n","\u001b[32m[12/28 23:42:53 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 139  total_loss: 1.502  loss_cls: 0.3395  loss_box_reg: 0.5891  loss_mask: 0.3602  loss_rpn_cls: 0.06655  loss_rpn_loc: 0.1384  time: 0.6289  data_time: 0.0076  lr: 0.00011597  max_mem: 1705M\n","\u001b[32m[12/28 23:43:05 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 159  total_loss: 1.505  loss_cls: 0.3154  loss_box_reg: 0.6054  loss_mask: 0.324  loss_rpn_cls: 0.07913  loss_rpn_loc: 0.1607  time: 0.6280  data_time: 0.0044  lr: 0.00013262  max_mem: 1705M\n","\u001b[32m[12/28 23:43:17 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 179  total_loss: 1.396  loss_cls: 0.3114  loss_box_reg: 0.5617  loss_mask: 0.3065  loss_rpn_cls: 0.06719  loss_rpn_loc: 0.1448  time: 0.6267  data_time: 0.0049  lr: 0.00014927  max_mem: 1705M\n","\u001b[32m[12/28 23:43:29 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 199  total_loss: 1.184  loss_cls: 0.2465  loss_box_reg: 0.4992  loss_mask: 0.2731  loss_rpn_cls: 0.06394  loss_rpn_loc: 0.1397  time: 0.6237  data_time: 0.0046  lr: 0.00016592  max_mem: 1705M\n","\u001b[32m[12/28 23:43:41 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 219  total_loss: 1.245  loss_cls: 0.2678  loss_box_reg: 0.5029  loss_mask: 0.273  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.1396  time: 0.6220  data_time: 0.0059  lr: 0.00018257  max_mem: 1705M\n","\u001b[32m[12/28 23:43:54 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 239  total_loss: 1.14  loss_cls: 0.2316  loss_box_reg: 0.458  loss_mask: 0.2666  loss_rpn_cls: 0.04481  loss_rpn_loc: 0.1334  time: 0.6240  data_time: 0.0047  lr: 0.00019922  max_mem: 1705M\n","\u001b[32m[12/28 23:44:06 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 259  total_loss: 1.17  loss_cls: 0.232  loss_box_reg: 0.4557  loss_mask: 0.2755  loss_rpn_cls: 0.05793  loss_rpn_loc: 0.1377  time: 0.6217  data_time: 0.0042  lr: 0.00021587  max_mem: 1705M\n","\u001b[32m[12/28 23:44:18 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 279  total_loss: 1.059  loss_cls: 0.2179  loss_box_reg: 0.4056  loss_mask: 0.2414  loss_rpn_cls: 0.04811  loss_rpn_loc: 0.1344  time: 0.6194  data_time: 0.0045  lr: 0.00023252  max_mem: 1705M\n","\u001b[32m[12/28 23:44:32 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 1.067  loss_cls: 0.2098  loss_box_reg: 0.4002  loss_mask: 0.2697  loss_rpn_cls: 0.04202  loss_rpn_loc: 0.1274  time: 0.6207  data_time: 0.0036  lr: 0.00024917  max_mem: 1705M\n","\u001b[32m[12/28 23:44:32 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:03:04 (0.6207 s / it)\n","\u001b[32m[12/28 23:44:32 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:06 (0:00:01 on hooks)\n","\u001b[32m[12/28 23:44:32 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    Uva     | 583          |\n","|            |              |\u001b[0m\n","\u001b[32m[12/28 23:44:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[12/28 23:44:32 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n","\u001b[32m[12/28 23:44:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.12 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/28 23:44:32 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"]}]},{"cell_type":"markdown","source":["Evaluacion"],"metadata":{"id":"LTeB11tfZUH-"}},{"cell_type":"code","source":["# Inference should use the config with parameters that are used in training\n","# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n","predictor = DefaultPredictor(cfg)\n","\n","dir_path = \"/content/drive/MyDrive/Mask RCNN/dataset-detectron/\"\n","with open(dir_path+\"dataset.json\", 'r') as file:\n","  #train = json.load(file)[\"train\"]\n","  val = json.load(file)[\"val\"]\n","  predictor = DefaultPredictor(cfg)\n","\n","from detectron2.utils.visualizer import ColorMode\n","\n","preds =[]\n","\n","for d in val:\n","  print(d[\"file_name\"])    \n","  im = cv2.imread(d[\"file_name\"])\n","  real_len = len(d[\"annotations\"])\n","  outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n","  pred_len = len(outputs[\"instances\"])\n","  preds.append([d[\"file_name\"],real_len,pred_len])\n","  #print(\"REAL NUM:\",real_len,\" PRED NUM:\",pred_len)\n","        \n","  v = Visualizer(im[:, :, ::-1],\n","        metadata=metadata, \n","        scale=0.5, \n","        instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n","      )\n","  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  cv2_imshow(out.get_image()[:, :, ::-1])\n","        \n","print(\"Nombre  |  Cantidad Real  | Cantidad Predecida\")\n","for i in preds:\n","  print(i[0],i[1],i[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15w85-qoT7oBJ8dU7Rs21UD4pboZi8lWt"},"id":"hqu4__SxZWKG","executionInfo":{"status":"ok","timestamp":1640910510614,"user_tz":180,"elapsed":13379,"user":{"displayName":"Omar Pavez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16127216402199155313"}},"outputId":"8d8fbbf8-e431-4031-8253-900d964703ff"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}